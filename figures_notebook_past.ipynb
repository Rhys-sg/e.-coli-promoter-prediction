{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OLD Figure S3\n",
    "---------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import ttest_ind\n",
    "import numpy as np\n",
    "from itertools import combinations, chain\n",
    "\n",
    "def get_file_mse_effect(file_names, data_for_plot):\n",
    "    all_combos = list(chain.from_iterable(combinations(file_names, i) for i in range(1, len(file_names) + 1)))\n",
    "    file_mse = {tuple(sorted(combo)): None for combo in all_combos}\n",
    "    \n",
    "    for combo_str, mse in [(row[2], row[1]) for row in data_for_plot]:\n",
    "        combo_key = tuple(sorted(combo_str.split(', ')))\n",
    "        file_mse[combo_key] = mse\n",
    "\n",
    "    mse_effect = {file: [] for file in file_names}\n",
    "    \n",
    "    for combo, value in file_mse.items():\n",
    "        for file in file_names:\n",
    "            if file in combo:\n",
    "                continue\n",
    "            extended_combo = tuple(sorted(combo + (file,)))\n",
    "            mse_diff = value - file_mse.get(extended_combo, 0)\n",
    "            mse_effect[file].append(mse_diff)\n",
    "    \n",
    "    return file_mse, mse_effect\n",
    "\n",
    "def group_mse_by_count(file_mse, file_of_interest, total_files):\n",
    "    grouped = {True: {i: [] for i in range(1, total_files + 1)},\n",
    "               False: {i: [] for i in range(1, total_files + 1)}}\n",
    "    \n",
    "    for combo, mse in file_mse.items():\n",
    "        included = file_of_interest in combo\n",
    "        grouped[included][len(combo)].append(mse)\n",
    "    \n",
    "    return grouped[True], grouped[False]\n",
    "\n",
    "def plot_mse_distributions(include_mse, exclude_mse, start_from, end_at, file_of_interest):\n",
    "    num_plots = end_at - start_from + 1\n",
    "    n_cols = 2\n",
    "    n_rows = (num_plots + n_cols - 1) // n_cols\n",
    "\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(n_cols * 6, n_rows * 5))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for idx, i in enumerate(range(start_from, end_at + 1)):\n",
    "        inc, exc = include_mse[i], exclude_mse[i]\n",
    "\n",
    "        if len(inc) > 1 and len(exc) > 1:\n",
    "            t_stat, p_val = ttest_ind(inc, exc, equal_var=False)\n",
    "            sig = \" (Significant)\" if p_val < 0.05 else \"\"\n",
    "            print(f\"{i} Files: t-stat = {t_stat:.4f}, p = {p_val:.4f}{sig}\")\n",
    "        else:\n",
    "            print(f\"{i} Files: Not enough data for t-test.\")\n",
    "\n",
    "        sns.kdeplot(inc, label='Including', fill=True, warn_singular=False, ax=axes[idx])\n",
    "        sns.kdeplot(exc, label='Excluding', fill=True, warn_singular=False, ax=axes[idx])\n",
    "\n",
    "        axes[idx].set_title(f'MSE Distribution for {i} Files')\n",
    "        axes[idx].set_xlabel('MSE Value')\n",
    "        axes[idx].set_ylabel('Density')\n",
    "        axes[idx].set_xlim(-7, 0)\n",
    "        axes[idx].legend(title='Condition')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return fig\n",
    "\n",
    "# Main script\n",
    "file_names = pd.read_csv('Data/LaFleur_supp.csv')['File Name'].unique()\n",
    "data_for_plot = pd.read_csv('Data/data_comparison.csv').values\n",
    "file_of_interest = 'Urtecho et al'\n",
    "start_from, end_at = 3, 6\n",
    "\n",
    "file_mse, mse_effect = get_file_mse_effect(file_names, data_for_plot)\n",
    "include_mse, exclude_mse = group_mse_by_count(file_mse, file_of_interest, len(file_names))\n",
    "fig = plot_mse_distributions(include_mse, exclude_mse, start_from, end_at or len(file_names) - 1, file_of_interest)\n",
    "\n",
    "# Save the figure\n",
    "fig.savefig('Figures/FigureS3_option1.pdf', dpi=300, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Load file names\n",
    "file_names = pd.read_csv('Data/LaFleur_supp.csv')['File Name'].unique()\n",
    "target_includes = ['La Fleur et al', 'Urtecho et al']\n",
    "file_names = [f for f in file_names if f in target_includes]\n",
    "\n",
    "data_df = pd.read_csv('Data/data_comparison.csv')\n",
    "data = data_df[['Number of Files', 'MSE', 'Name']].values\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "colors = {\n",
    "    'La Fleur et al': 'cornflowerblue',\n",
    "    'Urtecho et al': 'mediumseagreen'\n",
    "}\n",
    "\n",
    "x_all = sorted(set(int(n) for n, _, _ in data))\n",
    "\n",
    "# Scatter plot\n",
    "##scatter_data = [(int(n), l) for n, l, _ in data]\n",
    "##x_vals, y_vals = zip(*scatter_data)\n",
    "##ax.scatter(x_vals, y_vals, s=100, alpha=0.2, color='grey')\n",
    "\n",
    "# Boxplots\n",
    "labeled=True\n",
    "for x in x_all:\n",
    "    y_vals = [l for n, l, combo in data if int(n) == x]\n",
    "    ax.boxplot([y_vals], positions=[x], widths=0.3, patch_artist=True,\n",
    "                   boxprops=dict(facecolor='grey'),\n",
    "                   medianprops=dict(color='black'), \n",
    "                   label=\"All combinations\" if labeled else None)\n",
    "    labeled=False\n",
    "    for i, file_name in enumerate(target_includes):\n",
    "        y_vals = [l for n, l, combo in data if int(n) == x and file_name in str(combo)]\n",
    "        if not y_vals:\n",
    "            continue\n",
    "\n",
    "        # Offset x slightly for visual separation\n",
    "        offset = -0.25 if i == 0 else 0.25\n",
    "        ax.boxplot([y_vals], positions=[x + offset], widths=0.2, patch_artist=True,\n",
    "                   boxprops=dict(facecolor=colors[file_name]), showfliers=False,\n",
    "                   medianprops=dict(color='black'),\n",
    "                   label=f\"With {file_name}\" if x == x_all[0] else None)\n",
    "\n",
    "ax.set_xticks(x_all)\n",
    "ax.set_xticklabels(x_all)\n",
    "\n",
    "ax.set_xlabel('Number of Datasets')\n",
    "ax.set_ylabel('log10(MSE)')\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save the figure\n",
    "fig.savefig('Figures/Figure2.pdf', dpi=300, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OLD Saliency ploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model  # type: ignore\n",
    "\n",
    "# -------------------- Data Preprocessing Functions --------------------\n",
    "\n",
    "def combine_columns(df):\n",
    "    X = df['Promoter Sequence'].astype(str)\n",
    "    y = df['Normalized Observed log(TX/Txref)']\n",
    "    return X, y\n",
    "\n",
    "def padded_one_hot_encode(seq):\n",
    "    mapping = {'A': [1,0,0,0], 'C': [0,1,0,0], 'G': [0,0,1,0], 'T': [0,0,0,1], '0': [0,0,0,0]}\n",
    "    return [mapping[n.upper()] for n in seq]\n",
    "\n",
    "def preprocess_sequences(X, max_length=150):\n",
    "    return np.array([padded_one_hot_encode(seq.zfill(max_length)) for seq in X])\n",
    "\n",
    "\n",
    "# ----------------------- Generate Saliency Maps -----------------------\n",
    "\n",
    "def generate_saliency_map(model, sequence):\n",
    "    input_tensor = tf.convert_to_tensor(sequence[np.newaxis, ...], dtype=tf.float32)\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(input_tensor)\n",
    "        prediction = model(input_tensor)[0, 0]\n",
    "    gradient = tape.gradient(prediction, input_tensor)\n",
    "    gradient = tf.norm(gradient, axis=-1)\n",
    "    return (gradient / tf.reduce_max(gradient)).numpy()\n",
    "\n",
    "def plot_saliency_map_grid(\n",
    "    model_filename,\n",
    "    data,\n",
    "    num_samples=100,\n",
    "    random_state=42,\n",
    "    sort_by_prediction=False,\n",
    "    title=None,\n",
    "    colorbar=False,\n",
    "):\n",
    "    model = load_model(model_filename)\n",
    "\n",
    "    sequences = data.sample(n=min(num_samples, len(data)), random_state=random_state)['Promoter Sequence']\n",
    "    sequences = preprocess_sequences(sequences)\n",
    "\n",
    "    saliency_maps = []\n",
    "    predictions = []\n",
    "\n",
    "    for seq in sequences:\n",
    "        pred = model(tf.convert_to_tensor(seq[np.newaxis, ...], dtype=tf.float32))[0, 0].numpy()\n",
    "        saliency = np.abs(generate_saliency_map(model, seq))\n",
    "        saliency = np.nan_to_num(saliency)\n",
    "        predictions.append(pred)\n",
    "        saliency_maps.append(saliency)\n",
    "\n",
    "    if sort_by_prediction:\n",
    "        saliency_maps = [saliency_maps[i] for i in np.argsort(predictions)]\n",
    "\n",
    "    saliency_matrix = np.vstack(saliency_maps)\n",
    "\n",
    "    im = plt.imshow(\n",
    "        saliency_matrix, \n",
    "        cmap='magma', \n",
    "        aspect='auto', \n",
    "        vmin=saliency_matrix.min(), \n",
    "        vmax=saliency_matrix.max()\n",
    "    )\n",
    "    if colorbar:\n",
    "        plt.colorbar(im, label='Gradient Saliency')\n",
    "    plt.xticks([]); plt.yticks([])\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save the figure\n",
    "    plt.savefig('Figures/Figure3.pdf', dpi=300, bbox_inches='tight')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "data = pd.read_csv('Data/LaFleur_supp.csv')\n",
    "\n",
    "plot_saliency_map_grid(\n",
    "    model_filename='Models/CNN_6_1_2.keras',\n",
    "    data=data,\n",
    "    num_samples=100,\n",
    "    random_state=1,\n",
    "    sort_by_prediction=True,\n",
    "    colorbar=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv('Data/repeat_evalute_each_file.csv', index_col=0)\n",
    "\n",
    "file_names = []\n",
    "cv_self = []\n",
    "cv_all = []\n",
    "\n",
    "for i in range(0, len(df.columns), 2):\n",
    "    col_self = df.columns[i]\n",
    "    col_all = df.columns[i+1]\n",
    "    file_name = col_self.replace(' (Self)', '')\n",
    "\n",
    "    self_values = df[col_self]\n",
    "    all_values = df[col_all]\n",
    "\n",
    "    cv_s = self_values.std() / self_values.mean() if not self_values.empty else None\n",
    "    cv_a = all_values.std() / all_values.mean() if not all_values.empty else None\n",
    "\n",
    "    file_names.append(file_name)\n",
    "    cv_self.append(cv_s)\n",
    "    cv_all.append(cv_a)\n",
    "\n",
    "cv_df = pd.DataFrame({\n",
    "    \"File Name\": file_names,\n",
    "    \"Coefficient of Variation (Self)\": cv_self,\n",
    "    \"Coefficient of Variation (All)\": cv_all\n",
    "})\n",
    "\n",
    "# Merge with file name counts\n",
    "file_name_counts = pd.read_csv('Data/LaFleur_supp.csv')['File Name'].value_counts()\n",
    "cv_df = cv_df.merge(file_name_counts.rename_axis('File Name').reset_index(), on='File Name')\n",
    "\n",
    "# Rename, reorder columns\n",
    "cv_df.rename(columns={'File Name' : 'Dataset', 'count': 'Dataset Size'}, inplace=True)\n",
    "cv_df = cv_df[['Dataset', 'Dataset Size', 'Coefficient of Variation (Self)', 'Coefficient of Variation (All)']]\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "cv_df.to_csv('Figures/Table1.csv', index=False)\n",
    "\n",
    "\n",
    "cv_df"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
